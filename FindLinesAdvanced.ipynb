{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 \n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib.image as mpimg\n",
    "import glob \n",
    "font = cv2.FONT_HERSHEY_SIMPLEX\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Fn for collecting matrix of objp's and image points and calibrating\n",
    "def get_img_pts_calib(calib_image_set):\n",
    "    objpoints = []\n",
    "    objp = np.zeros((6*9, 3), np.float32)\n",
    "    objp[:,:2] = np.mgrid[0:9, 0:6].T.reshape(-1, 2)\n",
    "    imgpoints = []\n",
    "    nx, ny = 9, 6\n",
    "    for fname in calib_image_set:\n",
    "        img = mpimg.imread(fname)\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "        ret, corners = cv2.findChessboardCorners(gray, (nx, ny), None)\n",
    "        if ret == True: \n",
    "            objpoints.append(objp)\n",
    "            imgpoints.append(corners)\n",
    "            cv2.drawChessboardCorners(img, (nx, ny), corners, ret)\n",
    "    return objpoints, imgpoints\n",
    "\n",
    "#\tNow that we have the matrices (imgpoints and objpoints) we can calibrat & undistort the images\n",
    "def cal_undistort(img, objpoints, imgpoints):\n",
    "    ret, mtx, dist, rvecs, tvecs = cv2.calibrateCamera(objpoints, imgpoints, (img.shape[:2]), None, None)\n",
    "    undistorted_image = cv2.undistort(img, mtx, dist, None, mtx)\n",
    "    return undistorted_image       \n",
    "\n",
    "#Method for plotting before and after\n",
    "def plotting(img1, img2, title1 ='title1', title2 = 'title2', gray = 'no'):\n",
    "    f, (ax1, ax2) = plt.subplots(1, 2, figsize=(24, 9))\n",
    "    f.tight_layout()\n",
    "    ax1.imshow(img1)\n",
    "    ax1.set_title(title1, fontsize=50)\n",
    "    if gray == 'no':\n",
    "        ax2.imshow(img2)\n",
    "    else:\n",
    "        ax2.imshow(img2, cmap='gray')\n",
    "    ax2.set_title(title2, fontsize=50)\n",
    "    plt.subplots_adjust(left=0., right=1, top=0.9, bottom=0.)\n",
    "\n",
    "#Getting images to test on\n",
    "chsbrd_images = glob.glob('CarND-Advanced-Lane-Lines/camera_cal/calibration*.jpg')\n",
    "test_images = glob.glob('CarND-Advanced-Lane-Lines/test_images/test*.jpg')\n",
    "\n",
    "objpoints, imgpoints = get_img_pts_calib(chsbrd_images)\n",
    "#Print a test image before and after undistortion\n",
    "test_image = mpimg.imread(test_images[2])\n",
    "#Reading in a single image:...\n",
    "#      test_image = mpimg.imread('CarND-Advanced-Lane-Lines/test_images/straight_lines2.jpg')\n",
    "undistorted = cal_undistort(test_image, objpoints, imgpoints)\n",
    "plotting(test_image, undistorted, 'Original Image here:', 'undistorted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grad Thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now define the methods for the 3 gradient threshold techniques\n",
    "def abs_sobel_thresh(img, orient='x', s_kernel = 3, thresh=(0,255)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    if orient == 'x':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = s_kernel))\n",
    "    if orient == 'y':\n",
    "        abs_sobel = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = s_kernel))\n",
    "    scaled_sobel = np.uint8(255*abs_sobel/np.max(abs_sobel))\n",
    "    sbinary = np.zeros_like(scaled_sobel)\n",
    "    sbinary[(scaled_sobel > thresh[0]) & (scaled_sobel <= thresh[1])] = 1\n",
    "    return sbinary \n",
    "\n",
    "def mag_thresh(img, s_kernel= 3, thresh=(0, 255)): \n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    sobelx = cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = s_kernel)\n",
    "    sobely = cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = s_kernel)\n",
    "    gradmag = np.sqrt(np.square(sobelx) + np.square(sobely))\n",
    "    scale_factor = np.max(gradmag)/255\n",
    "    gradmag = (gradmag/scale_factor).astype(np.uint8)\n",
    "    binary_output = np.zeros_like(gradmag)\n",
    "    binary_output[(gradmag >= thresh[0]) & (gradmag < thresh[1])] = 1\n",
    "    return binary_output \n",
    "\n",
    "def dir_thresh(img, s_kernel=3, thresh=(0, np.pi/2)):\n",
    "    gray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n",
    "    abs_sobelx = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 1, 0, ksize = s_kernel))\n",
    "    abs_sobely = np.absolute(cv2.Sobel(gray, cv2.CV_64F, 0, 1, ksize = s_kernel))\n",
    "    grad_dir = np.arctan2(abs_sobelx, abs_sobely)\n",
    "    bin_mask = np.zeros_like(grad_dir)\n",
    "    bin_mask[(grad_dir > thresh[0]) & (grad_dir < thresh[1])] = 1\n",
    "    return bin_mask\n",
    "\n",
    "# Now define a method for combining the three methods: \n",
    "#THIS SHOULD CHANGE AS I TUNE PARAMETERS!\n",
    "def combine_grad_thresh(img):\n",
    "    #Run above methods with selected parameters for thresh & ksize\n",
    "    gradx = abs_sobel_thresh(img, orient='x', s_kernel=3, thresh=(20, 100))\n",
    "    grady = abs_sobel_thresh(img, orient='y', s_kernel=3, thresh=(5, 100))\n",
    "    mag_binary = mag_thresh(img, s_kernel=5, thresh=(30, 100))\n",
    "    dir_binary = dir_thresh(img, s_kernel=11, thresh=(0.7, 1.3))\n",
    "    #make a combination of them...\n",
    "    combined_sobel = np.zeros_like(dir_binary)\n",
    "    combined_sobel[(gradx == 1) & (grady == 1) | ((mag_binary == 1) & ( dir_binary ==1)) ] = 1\n",
    "    return combined_sobel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Color Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Color thresholding, taking the saturation channel from the HLS color space\n",
    "def hls_saturation(img, thresh=(90, 255)):\n",
    "    hls = cv2.cvtColor(img, cv2.COLOR_RGB2HLS)\n",
    "    s = hls[:,:,2]\n",
    "    binary_s = np.zeros_like(s)\n",
    "    binary_s[(s >= thresh[0]) & (s <= thresh[1])] = 1\n",
    "    return binary_s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combined Color and Grad Thresh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Now, COMBINE color and grad!!!!\n",
    "def combined(img):\n",
    "    #grd = combine_grad_thresh(img)\n",
    "    grd = abs_sobel_thresh(img, orient='x', s_kernel = 3, thresh=(5,100))\n",
    "    sat = hls_saturation(img)\n",
    "    comb_bin = np.zeros_like(grd)\n",
    "    comb_bin[(grd == 1) & (sat == 1)] = 1\n",
    "    return comb_bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lines_detected = combined(undistorted)\n",
    "plotting(undistorted, lines_detected, 'undist', 'thresg', 'yes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#### Prespective Transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def transform(img):\n",
    "    (h, w) = (img.shape[0], img.shape[1])\n",
    "    src = np.float32([[w // 2 - 76, h * .625], [w // 2 + 76, h * .625], [-100, h], [w + 100, h]])\n",
    "    dest = np.float32([[100, 0], [w - 100, 0], [100, h], [w - 100, h]])\n",
    "    M = cv2.getPerspectiveTransform(src, dest)\n",
    "    Minv = cv2.getPerspectiveTransform(dest, src)\n",
    "    transformed = cv2.warpPerspective(img, M, (w, h))\n",
    "    return transformed, M, Minv\n",
    "\n",
    "#First, transform perspective of the actual undistorted pic\n",
    "top_down, M, Minv = transform(undistorted)\n",
    "plotting(undistorted, top_down, 'Undistorted photo', 'Transformed undistorted') \n",
    "\n",
    "# Then of the one with all processing\n",
    "top_down = transform(lines_detected)[0]\n",
    "plotting(lines_detected, top_down, 'Processed pic: ', 'Transformed processed', 'yes') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
